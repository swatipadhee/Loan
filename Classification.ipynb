{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7be78a3-7bf7-4c79-a15b-7a6b669a3830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55028a9e-df19-4165-b054-73a71f0969c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100)  # Limit column width for better readability\n",
    "pd.set_option('display.max_rows', None)  # Display all rows\n",
    "pd.set_option('display.max_columns', None)  # Display all columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29d68ec8-a5d1-4a55-b45e-526b258aecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and testing data\n",
    "train_data = pd.read_csv(r'C:\\Users\\padhee.3\\Downloads\\Take Home Project\\training_processed_data.csv')  # Replace with your training file path\n",
    "inference_data = pd.read_csv(r'C:\\Users\\padhee.3\\Downloads\\Take Home Project\\testing_processed_data.csv')    # Replace with your testing file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f16941b1-5d2f-4a87-a60e-3a9ff3b3127a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'loan_amnt', 'term', 'int_rate', 'emp_length', 'home_ownership',\n",
      "       'annual_inc', 'purpose', 'percent_bc_gt_75', 'bc_util', 'dti',\n",
      "       'inq_last_6mths', 'mths_since_recent_inq', 'revol_util',\n",
      "       'total_bc_limit', 'tot_cur_bal', 'bad_flag'],\n",
      "      dtype='object')\n",
      "Index(['id', 'loan_amnt', 'term', 'int_rate', 'emp_length', 'home_ownership',\n",
      "       'annual_inc', 'purpose', 'percent_bc_gt_75', 'bc_util', 'dti',\n",
      "       'inq_last_6mths', 'mths_since_recent_inq', 'revol_util',\n",
      "       'total_bc_limit', 'tot_cur_bal', 'bad_flag'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_data.columns)\n",
    "print(inference_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eae0df1a-e5d1-468b-ba0c-1bb3e8aeef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'id' column \n",
    "if 'id' in train_data.columns:\n",
    "    train_data = train_data.drop(columns=['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e127d421-e88a-4106-ac59-e672f04b85bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>purpose</th>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <th>bc_util</th>\n",
       "      <th>dti</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_recent_inq</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>tot_cur_bal</th>\n",
       "      <th>bad_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7550</td>\n",
       "      <td>36 months</td>\n",
       "      <td>0.1624</td>\n",
       "      <td>3.0</td>\n",
       "      <td>RENT</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>100.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>8.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.720</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>5759.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27050</td>\n",
       "      <td>36 months</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>10.0</td>\n",
       "      <td>OWN</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>25.0</td>\n",
       "      <td>53.9</td>\n",
       "      <td>22.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.612</td>\n",
       "      <td>35700.0</td>\n",
       "      <td>114834.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt        term  int_rate  emp_length home_ownership  annual_inc  \\\n",
       "0       7550   36 months    0.1624         3.0           RENT     28000.0   \n",
       "1      27050   36 months    0.1099        10.0            OWN     55000.0   \n",
       "\n",
       "              purpose  percent_bc_gt_75  bc_util    dti  inq_last_6mths  \\\n",
       "0  debt_consolidation             100.0     96.0   8.40             0.0   \n",
       "1  debt_consolidation              25.0     53.9  22.87             0.0   \n",
       "\n",
       "   mths_since_recent_inq  revol_util  total_bc_limit  tot_cur_bal  bad_flag  \n",
       "0                   17.0       0.720          4000.0       5759.0       0.0  \n",
       "1                    8.0       0.612         35700.0     114834.0       0.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "368bd245-7350-4fdc-b974-a5e63db75f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      "bad_flag\n",
      "0.0    176329\n",
      "1.0     13128\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio: 0.07\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of the target variable\n",
    "class_counts = train_data['bad_flag'].value_counts()\n",
    "print(\"Class Distribution:\")\n",
    "print(class_counts)\n",
    "\n",
    "# Calculate imbalance ratio\n",
    "imbalance_ratio = class_counts.min() / class_counts.max()\n",
    "print(f\"Imbalance Ratio: {imbalance_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf1e248-535b-46f5-ac76-439454f954ae",
   "metadata": {},
   "source": [
    "###An imbalance ratio of 0.07 indicates a highly imbalanced dataset, with the majority class being much more frequent than the minority class. This will likely cause the model to be biased towards predicting the majority class, resulting in poor performance for the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92be100-c469-4319-9f3f-85acf2eae47d",
   "metadata": {},
   "source": [
    "#We can try oversampling, undersampling, or weighted loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9e78920-daca-43d5-bd76-4b57276c7687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical and numerical columns\n",
    "categorical_columns = ['purpose', 'term', 'home_ownership']  # Replace with actual categorical column names\n",
    "target_column = 'bad_flag'\n",
    "\n",
    "# Automatically detect numerical columns by excluding categorical and target columns\n",
    "numerical_columns = [col for col in train_data.columns if col not in categorical_columns + [target_column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d808545a-2980-4e5c-8519-07b27a999b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Class Distribution:\n",
      "bad_flag\n",
      "1.0    13128\n",
      "0.0    13128\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = train_data[train_data[target_column] == 0]\n",
    "df_minority = train_data[train_data[target_column] == 1]\n",
    "\n",
    "# Undersample the majority class using stratified sampling\n",
    "df_majority_undersampled = resample(\n",
    "    df_majority,\n",
    "    replace=False,              # Sample without replacement\n",
    "    n_samples=len(df_minority), # Match minority class size\n",
    "    random_state=42,            # For reproducibility\n",
    "    stratify=df_majority[target_column]  # Stratify to preserve class distribution\n",
    ")\n",
    "\n",
    "# Combine undersampled majority class with minority class\n",
    "df_train_balanced = pd.concat([df_majority_undersampled, df_minority])\n",
    "\n",
    "# Shuffle the dataset\n",
    "df_train_balanced = df_train_balanced.sample(frac=1, random_state=42)\n",
    "\n",
    "# Verify the new distribution\n",
    "print(\"Balanced Class Distribution:\")\n",
    "print(df_train_balanced[target_column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b140e998-a885-470b-8f2a-85ea2d5b0905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories in 'home_ownership': ['MORTGAGE' 'RENT' 'OWN' 'OTHER' 'NONE']\n",
      "Categories in 'purpose': ['debt_consolidation' 'other' 'medical' 'credit_card' 'car' 'wedding'\n",
      " 'renewable_energy' 'vacation' 'home_improvement' 'major_purchase'\n",
      " 'small_business' 'moving' 'house']\n",
      "Categories in 'term': [' 36 months' ' 60 months']\n",
      "Categories in 'home_ownership': ['RENT' 'OWN' 'MORTGAGE' 'NONE' 'OTHER']\n",
      "Categories in 'purpose': ['debt_consolidation' 'home_improvement' 'credit_card' 'other'\n",
      " 'major_purchase' 'small_business' 'house' 'moving' 'medical' 'car'\n",
      " 'vacation' 'renewable_energy' 'wedding']\n",
      "Categories in 'term': [' 36 months' ' 60 months']\n"
     ]
    }
   ],
   "source": [
    "# Print unique categories\n",
    "categories = df_train_balanced['home_ownership'].unique()\n",
    "print(\"Categories in 'home_ownership':\", categories)\n",
    "\n",
    "categories = df_train_balanced['purpose'].unique()\n",
    "print(\"Categories in 'purpose':\", categories)\n",
    "\n",
    "categories = df_train_balanced['term'].unique()\n",
    "print(\"Categories in 'term':\", categories)\n",
    "\n",
    "categories = test_data['home_ownership'].unique()\n",
    "print(\"Categories in 'home_ownership':\", categories)\n",
    "\n",
    "categories = test_data['purpose'].unique()\n",
    "print(\"Categories in 'purpose':\", categories)\n",
    "\n",
    "categories = test_data['term'].unique()\n",
    "print(\"Categories in 'term':\", categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7625443-ae19-4cba-bb26-184f810c5ca8",
   "metadata": {},
   "source": [
    "###There is a mismatch in categories in purpose as inference data has an unseen category of renewable energy. Hence, for now, I will fit the encoding only on training data and address unseen categories to be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e892a2a4-24d7-4f62-bb28-7bb59650fe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target in the balanced data\n",
    "X = df_train_balanced.drop(columns=[target_column])\n",
    "y = df_train_balanced[target_column].values\n",
    "\n",
    "# Preprocessing pipeline for numerical and categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the preprocessor on the training data\n",
    "preprocessor.fit(X)\n",
    "\n",
    "# Apply transformations\n",
    "X_transformed = preprocessor.transform(X)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d006e76-a52a-4f29-b008-c8da5cecd084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tensor shape: torch.Size([21004, 32])\n",
      "y_train_tensor shape: torch.Size([21004, 1])\n"
     ]
    }
   ],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Check the size of X_train_tensor and y_train_tensor\n",
    "print(f\"X_train_tensor shape: {X_train_tensor.shape}\")\n",
    "print(f\"y_train_tensor shape: {y_train_tensor.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72c4f3bc-e215-414b-8019-dd24a201e19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for batching\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdd0f5b-d514-4234-81dc-3a9bd7125d64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
