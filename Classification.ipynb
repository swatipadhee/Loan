{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7be78a3-7bf7-4c79-a15b-7a6b669a3830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55028a9e-df19-4165-b054-73a71f0969c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100)  # Limit column width for better readability\n",
    "pd.set_option('display.max_rows', None)  # Display all rows\n",
    "pd.set_option('display.max_columns', None)  # Display all columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29d68ec8-a5d1-4a55-b45e-526b258aecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and testing data\n",
    "train_data = pd.read_csv(r'C:\\Users\\padhee.3\\Downloads\\Take Home Project\\training_processed_data.csv')  # Replace with your training file path\n",
    "inference_data = pd.read_csv(r'C:\\Users\\padhee.3\\Downloads\\Take Home Project\\testing_processed_data.csv')    # Replace with your testing file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f16941b1-5d2f-4a87-a60e-3a9ff3b3127a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'loan_amnt', 'term', 'int_rate', 'emp_length', 'home_ownership',\n",
      "       'annual_inc', 'purpose', 'percent_bc_gt_75', 'bc_util', 'dti',\n",
      "       'inq_last_6mths', 'mths_since_recent_inq', 'revol_util',\n",
      "       'total_bc_limit', 'tot_cur_bal', 'bad_flag'],\n",
      "      dtype='object')\n",
      "Index(['id', 'loan_amnt', 'term', 'int_rate', 'emp_length', 'home_ownership',\n",
      "       'annual_inc', 'purpose', 'percent_bc_gt_75', 'bc_util', 'dti',\n",
      "       'inq_last_6mths', 'mths_since_recent_inq', 'revol_util',\n",
      "       'total_bc_limit', 'tot_cur_bal', 'bad_flag'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_data.columns)\n",
    "print(inference_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eae0df1a-e5d1-468b-ba0c-1bb3e8aeef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'id' column \n",
    "if 'id' in train_data.columns:\n",
    "    train_data = train_data.drop(columns=['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e127d421-e88a-4106-ac59-e672f04b85bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>purpose</th>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <th>bc_util</th>\n",
       "      <th>dti</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_recent_inq</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>tot_cur_bal</th>\n",
       "      <th>bad_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7550</td>\n",
       "      <td>36 months</td>\n",
       "      <td>0.1624</td>\n",
       "      <td>3.0</td>\n",
       "      <td>RENT</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>100.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>8.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.720</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>5759.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27050</td>\n",
       "      <td>36 months</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>10.0</td>\n",
       "      <td>OWN</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>25.0</td>\n",
       "      <td>53.9</td>\n",
       "      <td>22.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.612</td>\n",
       "      <td>35700.0</td>\n",
       "      <td>114834.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt        term  int_rate  emp_length home_ownership  annual_inc  \\\n",
       "0       7550   36 months    0.1624         3.0           RENT     28000.0   \n",
       "1      27050   36 months    0.1099        10.0            OWN     55000.0   \n",
       "\n",
       "              purpose  percent_bc_gt_75  bc_util    dti  inq_last_6mths  \\\n",
       "0  debt_consolidation             100.0     96.0   8.40             0.0   \n",
       "1  debt_consolidation              25.0     53.9  22.87             0.0   \n",
       "\n",
       "   mths_since_recent_inq  revol_util  total_bc_limit  tot_cur_bal  bad_flag  \n",
       "0                   17.0       0.720          4000.0       5759.0       0.0  \n",
       "1                    8.0       0.612         35700.0     114834.0       0.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "368bd245-7350-4fdc-b974-a5e63db75f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      "bad_flag\n",
      "0.0    176329\n",
      "1.0     13128\n",
      "Name: count, dtype: int64\n",
      "Imbalance Ratio: 0.07\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of the target variable\n",
    "class_counts = train_data['bad_flag'].value_counts()\n",
    "print(\"Class Distribution:\")\n",
    "print(class_counts)\n",
    "\n",
    "# Calculate imbalance ratio\n",
    "imbalance_ratio = class_counts.min() / class_counts.max()\n",
    "print(f\"Imbalance Ratio: {imbalance_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf1e248-535b-46f5-ac76-439454f954ae",
   "metadata": {},
   "source": [
    "###An imbalance ratio of 0.07 indicates a highly imbalanced dataset, with the majority class being much more frequent than the minority class. This will likely cause the model to be biased towards predicting the majority class, resulting in poor performance for the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92be100-c469-4319-9f3f-85acf2eae47d",
   "metadata": {},
   "source": [
    "#We can try oversampling, undersampling, or weighted loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9e78920-daca-43d5-bd76-4b57276c7687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical and numerical columns\n",
    "categorical_columns = ['purpose', 'term', 'home_ownership']  # Replace with actual categorical column names\n",
    "target_column = 'bad_flag'\n",
    "\n",
    "# Automatically detect numerical columns by excluding categorical and target columns\n",
    "numerical_columns = [col for col in train_data.columns if col not in categorical_columns + [target_column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d808545a-2980-4e5c-8519-07b27a999b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Class Distribution:\n",
      "bad_flag\n",
      "1.0    13128\n",
      "0.0    13128\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = train_data[train_data[target_column] == 0]\n",
    "df_minority = train_data[train_data[target_column] == 1]\n",
    "\n",
    "# Undersample the majority class using stratified sampling\n",
    "df_majority_undersampled = resample(\n",
    "    df_majority,\n",
    "    replace=False,              # Sample without replacement\n",
    "    n_samples=len(df_minority), # Match minority class size\n",
    "    random_state=42,            # For reproducibility\n",
    "    stratify=df_majority[target_column]  # Stratify to preserve class distribution\n",
    ")\n",
    "\n",
    "# Combine undersampled majority class with minority class\n",
    "df_train_balanced = pd.concat([df_majority_undersampled, df_minority])\n",
    "\n",
    "# Shuffle the dataset\n",
    "df_train_balanced = df_train_balanced.sample(frac=1, random_state=42)\n",
    "\n",
    "# Verify the new distribution\n",
    "print(\"Balanced Class Distribution:\")\n",
    "print(df_train_balanced[target_column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b140e998-a885-470b-8f2a-85ea2d5b0905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories in 'home_ownership': ['MORTGAGE' 'RENT' 'OWN' 'OTHER' 'NONE']\n",
      "Categories in 'purpose': ['debt_consolidation' 'other' 'medical' 'credit_card' 'car' 'wedding'\n",
      " 'renewable_energy' 'vacation' 'home_improvement' 'major_purchase'\n",
      " 'small_business' 'moving' 'house']\n",
      "Categories in 'term': [' 36 months' ' 60 months']\n",
      "Categories in 'home_ownership': ['RENT' 'OWN' 'MORTGAGE' 'NONE' 'OTHER']\n",
      "Categories in 'purpose': ['debt_consolidation' 'home_improvement' 'credit_card' 'other'\n",
      " 'major_purchase' 'small_business' 'house' 'moving' 'medical' 'car'\n",
      " 'vacation' 'renewable_energy' 'wedding']\n",
      "Categories in 'term': [' 36 months' ' 60 months']\n"
     ]
    }
   ],
   "source": [
    "# Print unique categories\n",
    "categories = df_train_balanced['home_ownership'].unique()\n",
    "print(\"Categories in 'home_ownership':\", categories)\n",
    "\n",
    "categories = df_train_balanced['purpose'].unique()\n",
    "print(\"Categories in 'purpose':\", categories)\n",
    "\n",
    "categories = df_train_balanced['term'].unique()\n",
    "print(\"Categories in 'term':\", categories)\n",
    "\n",
    "categories = test_data['home_ownership'].unique()\n",
    "print(\"Categories in 'home_ownership':\", categories)\n",
    "\n",
    "categories = test_data['purpose'].unique()\n",
    "print(\"Categories in 'purpose':\", categories)\n",
    "\n",
    "categories = test_data['term'].unique()\n",
    "print(\"Categories in 'term':\", categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7625443-ae19-4cba-bb26-184f810c5ca8",
   "metadata": {},
   "source": [
    "###There is a mismatch in categories in purpose as inference data has an unseen category of renewable energy. Hence, for now, I will fit the encoding only on training data and address unseen categories to be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e892a2a4-24d7-4f62-bb28-7bb59650fe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target in the balanced data\n",
    "X = df_train_balanced.drop(columns=[target_column])\n",
    "y = df_train_balanced[target_column].values\n",
    "\n",
    "# Preprocessing pipeline for numerical and categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit the preprocessor on the training data\n",
    "preprocessor.fit(X)\n",
    "\n",
    "# Apply transformations\n",
    "X_transformed = preprocessor.transform(X)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d006e76-a52a-4f29-b008-c8da5cecd084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tensor shape: torch.Size([21004, 32])\n",
      "y_train_tensor shape: torch.Size([21004, 1])\n"
     ]
    }
   ],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Check the size of X_train_tensor and y_train_tensor\n",
    "print(f\"X_train_tensor shape: {X_train_tensor.shape}\")\n",
    "print(f\"y_train_tensor shape: {y_train_tensor.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72c4f3bc-e215-414b-8019-dd24a201e19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for batching\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4bdd0f5b-d514-4234-81dc-3a9bd7125d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dfe877cf-3337-48ce-ac8d-8d1fb01bb26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 64  # Configurable number of neurons in the hidden layer\n",
    "model = NeuralNetwork(input_size, hidden_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16496ec0-01e7-413f-8315-7f8f0da1609e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Train Loss: 0.6533, Validation Loss: 0.6498\n",
      "Epoch 2/40, Train Loss: 0.6415, Validation Loss: 0.6443\n",
      "Epoch 3/40, Train Loss: 0.6363, Validation Loss: 0.6397\n",
      "Epoch 4/40, Train Loss: 0.6332, Validation Loss: 0.6382\n",
      "Epoch 5/40, Train Loss: 0.6315, Validation Loss: 0.6375\n",
      "Epoch 6/40, Train Loss: 0.6299, Validation Loss: 0.6390\n",
      "Epoch 7/40, Train Loss: 0.6280, Validation Loss: 0.6387\n",
      "Epoch 8/40, Train Loss: 0.6271, Validation Loss: 0.6373\n",
      "Epoch 9/40, Train Loss: 0.6264, Validation Loss: 0.6384\n",
      "Epoch 10/40, Train Loss: 0.6255, Validation Loss: 0.6397\n",
      "Epoch 11/40, Train Loss: 0.6241, Validation Loss: 0.6405\n",
      "Epoch 12/40, Train Loss: 0.6234, Validation Loss: 0.6378\n",
      "Epoch 13/40, Train Loss: 0.6227, Validation Loss: 0.6387\n",
      "Epoch 14/40, Train Loss: 0.6219, Validation Loss: 0.6404\n",
      "Epoch 15/40, Train Loss: 0.6213, Validation Loss: 0.6409\n",
      "Epoch 16/40, Train Loss: 0.6198, Validation Loss: 0.6387\n",
      "Epoch 17/40, Train Loss: 0.6194, Validation Loss: 0.6401\n",
      "Epoch 18/40, Train Loss: 0.6190, Validation Loss: 0.6385\n",
      "Epoch 19/40, Train Loss: 0.6180, Validation Loss: 0.6410\n",
      "Epoch 20/40, Train Loss: 0.6177, Validation Loss: 0.6397\n",
      "Epoch 21/40, Train Loss: 0.6168, Validation Loss: 0.6400\n",
      "Epoch 22/40, Train Loss: 0.6166, Validation Loss: 0.6403\n",
      "Epoch 23/40, Train Loss: 0.6155, Validation Loss: 0.6379\n",
      "Epoch 24/40, Train Loss: 0.6157, Validation Loss: 0.6395\n",
      "Epoch 25/40, Train Loss: 0.6153, Validation Loss: 0.6399\n",
      "Epoch 26/40, Train Loss: 0.6145, Validation Loss: 0.6427\n",
      "Epoch 27/40, Train Loss: 0.6143, Validation Loss: 0.6404\n",
      "Epoch 28/40, Train Loss: 0.6132, Validation Loss: 0.6389\n",
      "Epoch 29/40, Train Loss: 0.6130, Validation Loss: 0.6404\n",
      "Epoch 30/40, Train Loss: 0.6125, Validation Loss: 0.6430\n",
      "Epoch 31/40, Train Loss: 0.6122, Validation Loss: 0.6405\n",
      "Epoch 32/40, Train Loss: 0.6119, Validation Loss: 0.6419\n",
      "Epoch 33/40, Train Loss: 0.6120, Validation Loss: 0.6407\n",
      "Epoch 34/40, Train Loss: 0.6109, Validation Loss: 0.6424\n",
      "Epoch 35/40, Train Loss: 0.6108, Validation Loss: 0.6413\n",
      "Epoch 36/40, Train Loss: 0.6105, Validation Loss: 0.6416\n",
      "Epoch 37/40, Train Loss: 0.6100, Validation Loss: 0.6435\n",
      "Epoch 38/40, Train Loss: 0.6098, Validation Loss: 0.6438\n",
      "Epoch 39/40, Train Loss: 0.6099, Validation Loss: 0.6448\n",
      "Epoch 40/40, Train Loss: 0.6093, Validation Loss: 0.6421\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=20):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss/len(train_loader):.4f}, Validation Loss: {val_loss/len(val_loader):.4f}\")\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34694836-3d48-460e-a2db-8465ef8445e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6337\n",
      "Validation Precision: 0.6353\n",
      "Validation Recall: 0.6329\n",
      "Validation F1-Score: 0.6341\n",
      "Validation AUC: 0.6337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Add performance evaluation after training\n",
    "def evaluate_model(model, val_loader, y_val_tensor):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            outputs = model(X_batch)\n",
    "            preds = (outputs >= 0.5).int()  # Binary classification\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(y_batch)\n",
    "    \n",
    "    # Flatten the lists\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_preds)\n",
    "\n",
    "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Validation Precision: {precision:.4f}\")\n",
    "    print(f\"Validation Recall: {recall:.4f}\")\n",
    "    print(f\"Validation F1-Score: {f1:.4f}\")\n",
    "    print(f\"Validation AUC: {auc:.4f}\")\n",
    "\n",
    "# After training, evaluate the model on the validation set\n",
    "evaluate_model(model, val_loader, y_val_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8674a6-6a51-493e-ad45-22f4ce2e54f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
